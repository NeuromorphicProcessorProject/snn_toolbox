[paths]
path_wd =
dataset_path =
log_dir_of_current_run =
runlabel = test
filename_ann =
filename_parsed_model =
filename_snn =
filename_clamp_indices =
filepath_custom_objects =
class_idx_path =

[input]
model_lib = keras
dataset_format = npz
datagen_kwargs = {}
dataflow_kwargs = {}
poisson_input = False
input_rate = 1000
num_poisson_events_per_sample = -1
num_dvs_events_per_sample = 2000
eventframe_width = 10
label_dict = {}
chip_size = None
frame_gen_method =
is_x_first =
is_x_flipped =
is_y_flipped =
maxpool_subsampling = True
do_clip_three_sigma = True
keras_dataset =

[tools]
evaluate_ann = True
parse = True
normalize = True
convert = True
simulate = True
serialise_only = False

[normalization]
percentile = 99.9
normalization_schedule = False
online_normalization = False
diff_to_max_rate = 200
diff_to_min_rate = 100
timestep_fraction = 10

[conversion]
softmax_to_relu = False
maxpool_type = fir_max
max2avg_pool = False
spike_code = temporal_mean_rate
num_bits = 32

[simulation]
simulator = INI
duration = 200
dt = 1
batch_size = 1
num_to_test = 1
sample_idxs_to_test = []
reset_between_nth_sample = 1
top_k = 1
keras_backend = tensorflow
early_stopping = False

[spinnaker]
number_of_neurons_per_core = 64

[cell]
v_thresh = 1
tau_refrac = 0
v_reset = 0
v_rest = 0
cm = 1
tau_m = 1000
tau_syn_E = 0.01
tau_syn_I = 0.01
delay = 0
binarize_weights = False
quantize_weights = False
scaling_factor = 10000000
payloads = False
reset = Reset by subtraction
leak = False
bias_relaxation = False

[parameter_sweep]
param_values = []
param_name = v_thresh
param_logscale = False

[output]
log_vars = {}
plot_vars = {}
verbose = 1
overwrite = True
use_simple_labels = True
plotproperties = {
    'font.size': 13,
    'axes.titlesize': 'xx-large',
    'axes.labelsize': 'xx-large',
    'xtick.labelsize': 'xx-large',
    'xtick.major.size': 7,
    'xtick.minor.size': 5,
    'ytick.labelsize': 'xx-large',
    'ytick.major.size': 7,
    'ytick.minor.size': 5,
    'legend.fontsize': 'xx-large',
    'figure.figsize': (7, 6),
    'savefig.format': 'png'}

# Use the following section to specify sets of possible values that certain
# config settings may accept. Will be used in `bin.utils.update_setup` to test
# validity of config.

[restrictions]
model_libs = {'keras', 'lasagne', 'caffe', 'pytorch'}
dataset_formats = {'npz', 'jpg', 'aedat'}
frame_gen_method = {'signed_sum', 'rectified_sum'}
maxpool_types = {'fir_max', 'exp_max', 'avg_max'}
simulators_pyNN = {'nest', 'brian', 'neuron', 'spiNNaker'}
simulators_other = {'INI', 'brian2', 'MegaSim', 'loihi'}
simulators = %(simulators_pyNN)s | %(simulators_other)s
# Keras backends:
keras_backends = {'theano', 'tensorflow'}
# Spike coding mechanisms:
spike_codes = {'temporal_mean_rate', 'temporal_pattern', 'ttfs',
               'ttfs_dyn_thresh', 'ttfs_corrective'}
# Layers that have neurons with membrane potentials, from which we can measure spikes:
spiking_layers = {'Dense', 'Conv1D', 'Conv2D', 'DepthwiseConv2D', 'MaxPooling2D',
                  'AveragePooling2D', 'Sparse', 'SparseConv2D',
                  'SparseDepthwiseConv2D'}
# Layers that can be implemented by our spiking neuron simulators:
snn_layers = %(spiking_layers)s | {'Reshape', 'Flatten', 'Concatenate',
                                   'ZeroPadding2D'}
cellparams_pyNN = {'v_thresh', 'v_reset', 'v_rest', 'cm', 'tau_refrac',
                   'tau_m', 'tau_syn_E', 'tau_syn_I'}

log_vars = {'activations_n_b_l', 'spiketrains_n_b_l_t', 'input_b_l_t',
            'mem_n_b_l_t', 'synaptic_operations_b_t', 'neuron_operations_b_t',
            'all'}
plot_vars = {'activations', 'spiketrains', 'spikecounts', 'spikerates',
             'input_image', 'error_t', 'confusion_matrix', 'correlation',
             'hist_spikerates_activations', 'normalization_activations',
             'operations', 'v_mem', 'all'}
